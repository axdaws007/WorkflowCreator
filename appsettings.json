{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft.AspNetCore": "Warning",
      "Microsoft.SemanticKernel": "Information",
      "WorkflowCreator.Services": "Information",
      "WorkflowCreator.Controllers": "Information",
      "Microsoft.Extensions.Http": "Warning",
      "System.Net.Http.HttpClient": "Warning"
    },
    "Console": {
      "IncludeScopes": true,
      "TimestampFormat": "yyyy-MM-dd HH:mm:ss "
    }
  },
  "AllowedHosts": "*",

  // =================================================================
  // AI CONFIGURATION - HYBRID CLOUD + LOCAL SETUP
  // =================================================================
  "AI": {

    // CLOUD AI SERVICES (for Natural Language Understanding & Analysis)
    "Cloud": {
      // Primary provider: "OpenAI", "Azure", "Anthropic", or leave empty for local-only
      "Provider": "OpenAI",

      // Global cloud AI settings
      "Temperature": 0.7,
      "MaxTokens": 2000,
      "RequestTimeout": 30000,
      "MaxRetries": 3,
      "RetryDelay": 1000,

      // OpenAI Configuration
      "OpenAI": {
        // Get your API key from: https://platform.openai.com/api-keys
        // IMPORTANT: Replace with your actual API key
        "ApiKey": "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",

        // Recommended models for different use cases:
        // - "gpt-4o-mini": Fast, cost-effective, great for most workflows
        // - "gpt-4o": Higher quality for complex analysis
        // - "gpt-4": Premium quality (higher cost)
        // - "gpt-3.5-turbo": Budget option
        "ModelId": "gpt-4o-mini",

        // Optional: Organization ID if you're part of an OpenAI organization
        "OrganizationId": "",

        // Model-specific settings
        "AnalysisModel": "gpt-4o-mini",
        "FunctionCallingModel": "gpt-4o",

        // Advanced settings
        "TopP": 0.9,
        "FrequencyPenalty": 0.0,
        "PresencePenalty": 0.0,
        "StopSequences": []
      },

      // Azure OpenAI Configuration (alternative to OpenAI)
      "Azure": {
        // Your Azure OpenAI resource endpoint
        // Format: https://your-resource-name.openai.azure.com/
        "Endpoint": "https://your-resource.openai.azure.com/",

        // Azure OpenAI API key
        "ApiKey": "your-azure-openai-api-key",

        // Deployment name (not model name) from your Azure OpenAI resource
        "ModelId": "gpt-4",

        // API version for Azure OpenAI
        "ApiVersion": "2024-02-01",

        // Optional: Specific deployments for different purposes
        "AnalysisDeployment": "gpt-4-analysis",
        "FunctionDeployment": "gpt-4-functions"
      },

      // Anthropic Configuration (Claude models - future support)
      "Anthropic": {
        "ApiKey": "your-anthropic-api-key",
        "ModelId": "claude-3-sonnet-20240229",
        "MaxTokens": 4000
      }
    },

    // LOCAL AI SERVICES (for Code Generation & Privacy-Sensitive Operations)
    "Local": {
      // Local AI provider: "Ollama", "LocalAI", "LMStudio"
      "Provider": "Ollama",

      // Ollama service endpoint (default local installation)
      "Endpoint": "http://localhost:11434",

      // Primary model for SQL generation (download with: ollama pull codellama:7b)
      "ModelId": "codellama:7b",

      // Specialized models for different tasks
      "AnalysisModel": "llama3:8b", // For analysis if cloud AI unavailable
      "SqlModel": "codellama:7b", // Specialized for SQL generation
      "FunctionModel": "llama3:8b", // For function calling and complex logic
      "CodeModel": "codellama:7b", // Alternative code generation model

      // Local AI generation settings (lower temperature for more consistent code)
      "Temperature": 0.1,
      "MaxTokens": 3000,
      "TopK": 10,
      "TopP": 0.1,
      "RepeatPenalty": 1.1,
      "RequestTimeout": 60000,
      "MaxRetries": 2,

      // Model management
      "AutoPullModels": false, // Automatically download missing models
      "PreferredModels": [ // Priority order for model selection
        "codellama:7b",
        "llama3:8b"
      ]
    },

    // HYBRID CONFIGURATION
    "Hybrid": {
      // Use cloud AI for analysis and local AI for SQL generation
      "PreferCloudForAnalysis": true,

      // Fallback to local AI if cloud AI fails
      "EnableCloudFallback": false,

      // Cache analysis results to reduce API calls
      "EnableResultCaching": true,

      // Cache duration in minutes
      "CacheDurationMinutes": 60,

      // Load balancing between multiple local models
      "EnableLocalLoadBalancing": false
    },

    // PERFORMANCE & MONITORING
    "Performance": {
      // Timeout settings (in milliseconds)
      "AnalysisTimeout": 30000,
      "SqlGenerationTimeout": 60000,
      "HealthCheckTimeout": 10000,

      // Concurrent request limits
      "MaxConcurrentRequests": 5,
      "MaxCloudRequestsPerMinute": 20,
      "MaxLocalRequestsPerMinute": 100,

      // Monitoring
      "EnablePerformanceLogging": true,
      "EnableTokenUsageTracking": true,
      "LogSlowRequests": true,
      "SlowRequestThresholdMs": 5000
    }
  },

  // =================================================================
  // WORKFLOW SCHEMA CONFIGURATION
  // =================================================================
  "WorkflowSchema": {
    // Use external SQL schema file
    "UseSchemaFile": true,

    // Path to the schema file (relative to application root)
    "SchemaFile": "workflow-schema.sql",

    // Validate schema file exists on startup
    "ValidateSchemaOnStartup": true,

    // PAWS system configuration
    "DatabaseSchema": "paws",
    "DefaultProcessSeed": 0,
    "EnableReassignment": false,

    // SQL generation preferences
    "SqlDialect": "SqlServer",
    "IncludeComments": true,
    "IncludeTransactionBlocks": false,
    "UseParameterizedQueries": false
  },

  // =================================================================
  // CACHING CONFIGURATION
  // =================================================================
  "Caching": {
    "Memory": {
      "SizeLimit": 100000000, // 100MB memory cache limit
      "CompactionPercentage": 0.25, // Compact when 75% full
      "ExpirationScanFrequency": 300 // Scan every 5 minutes
    },

    "Workflow": {
      "AnalysisCache": {
        "DefaultExpiration": 3600, // 1 hour
        "MaxItems": 1000,
        "SlidingExpiration": true
      },
      "SqlCache": {
        "DefaultExpiration": 7200, // 2 hours  
        "MaxItems": 500,
        "SlidingExpiration": false
      }
    }
  },

  // =================================================================
  // HEALTH MONITORING & DIAGNOSTICS
  // =================================================================
  "HealthChecks": {
    "Enabled": true,
    "CheckIntervalSeconds": 30,
    "TimeoutSeconds": 10,

    "AI": {
      "EnableCloudHealthCheck": true,
      "EnableLocalHealthCheck": true,
      "FailureThresholdCount": 3,
      "SuccessThresholdCount": 2,
      "CheckIntervalSeconds": 60
    },

    "Endpoints": {
      "/health": {
        "Enabled": true,
        "RequireAuthorization": false
      },
      "/health/ready": {
        "Enabled": true,
        "RequireAuthorization": false
      }
    }
  },

  // =================================================================
  // APPLICATION FEATURES & TOGGLES
  // =================================================================
  "Features": {
    // Core workflow features
    "EnableWorkflowCreation": true,
    "EnableWorkflowReAnalysis": true,
    "EnableWorkflowDeletion": true,
    "EnableSqlGeneration": true,

    // AI features
    "EnableCloudAI": true,
    "EnableLocalAI": true,
    "EnableHybridMode": true,
    "EnableAIFallback": false,

    // Advanced features
    "EnableFunctionCalling": true,
    "EnableAdvancedAnalysis": true,
    "EnableBatchProcessing": false,
    "EnableWorkflowTemplates": false,

    // UI features
    "EnableRealTimeStatus": true,
    "EnableDarkMode": true,
    "EnableKeyboardShortcuts": true,
    "EnableAdvancedDiagnostics": true
  },

  // =================================================================
  // SECURITY CONFIGURATION
  // =================================================================
  "Security": {
    // API key validation
    "ValidateApiKeys": true,
    "MaskApiKeysInLogs": true,

    // Request validation
    "MaxRequestSize": 1048576, // 1MB max request size
    "EnableRequestValidation": true,
    "AllowedOrigins": [ "https://localhost", "http://localhost" ],

    // Content security
    "EnableContentSecurityPolicy": true,
    "AllowInlineScripts": false,
    "TrustedScriptSources": [ "'self'", "https://cdn.jsdelivr.net", "https://cdnjs.cloudflare.com" ]
  },

  // =================================================================
  // INTEGRATION SETTINGS
  // =================================================================
  "Integration": {
    // External services
    "EnableWebhooks": false,
    "EnableApiExport": false,
    "EnableSlackIntegration": false,
    "EnableTeamsIntegration": false,

    // Data export
    "EnableSqlExport": true,
    "EnableJsonExport": true,
    "EnableCsvExport": false,

    // Backup and recovery
    "EnableAutoBackup": false,
    "BackupIntervalHours": 24,
    "BackupRetentionDays": 30
  },

  // =================================================================
  // DEVELOPMENT & DEBUGGING
  // =================================================================
  "Development": {
    // Debug features (only active in Development environment)
    "EnableDetailedErrors": true,
    "EnableSqlPreview": true,
    "EnablePromptLogging": true,
    "EnableResponseLogging": false,
    "EnablePerformanceProfiling": true,

    // Mock services for testing
    "UseMockAIServices": false,
    "MockResponseDelay": 1000,

    // Sample data
    "IncludeSampleWorkflows": true,
    "AutoGenerateSampleData": false
  },

  // =================================================================
  // ENVIRONMENT-SPECIFIC OVERRIDES
  // =================================================================
  "EnvironmentSettings": {
    "Production": {
      "Logging.LogLevel.Default": "Warning",
      "AI.Performance.EnablePerformanceLogging": false,
      "Development.EnableDetailedErrors": false,
      "Security.EnableContentSecurityPolicy": true
    },

    "Staging": {
      "AI.Cloud.OpenAI.ModelId": "gpt-3.5-turbo",
      "AI.Performance.MaxCloudRequestsPerMinute": 10,
      "Features.EnableAdvancedDiagnostics": false
    }
  },

  // =================================================================
  // MODEL RECOMMENDATIONS & DOCUMENTATION
  // =================================================================
  "_ModelRecommendations": {
    "_comment": "Configuration guidance for different deployment scenarios",

    "CloudModels": {
      "Budget": "gpt-3.5-turbo (lowest cost, good quality)",
      "Balanced": "gpt-4o-mini (recommended - best cost/performance)",
      "Premium": "gpt-4o (highest quality, higher cost)",
      "Enterprise": "Azure OpenAI with gpt-4 (compliance, data residency)"
    },

    "LocalModels": {
      "Minimal": "codellama:7b (4GB RAM, good SQL generation)",
      "Recommended": "codellama:7b + llama3:8b (8GB RAM, best balance)"
    },

    "HybridSetups": {
      "CostOptimized": "OpenAI gpt-4o-mini + Ollama codellama:7b",
      "QualityFocused": "OpenAI gpt-4o + Ollama codellama:13b",
      "PrivacyFirst": "Ollama only with llama3:8b + codellama:7b",
      "Enterprise": "Azure OpenAI + Local models for sensitive data"
    }
  },

  // =================================================================
  // SETUP INSTRUCTIONS (REMOVE IN PRODUCTION)
  // =================================================================
  "_SetupInstructions": {
    "_comment": "Remove this section in production deployments",

    "QuickStart": [
      "1. Replace 'sk-your-openai-api-key-here' with your actual OpenAI API key",
      "2. Install Ollama: https://ollama.ai/download",
      "3. Download models: 'ollama pull codellama:7b' and 'ollama pull llama3:8b'",
      "4. Start Ollama service: 'ollama serve'",
      "5. Test setup at: /Workflow/TestConnection",
      "6. Create your first workflow at: /Workflow"
    ],

    "OpenAISetup": [
      "Visit: https://platform.openai.com/api-keys",
      "Create new API key",
      "Replace the placeholder in AI.Cloud.OpenAI.ApiKey",
      "Consider setting usage limits in OpenAI dashboard"
    ],

    "OllamaSetup": [
      "Install: https://ollama.ai/download",
      "Pull models: ollama pull codellama:7b",
      "Optional: ollama pull llama3:8b",
      "Start service: ollama serve",
      "Verify: curl http://localhost:11434/api/tags"
    ],

    "Troubleshooting": {
      "CommonIssues": [
        "API key invalid: Check OpenAI dashboard and regenerate if needed",
        "Ollama not found: Ensure service is running on port 11434",
        "Models not found: Use 'ollama list' to check downloaded models",
        "Slow responses: Consider using smaller models or adjusting timeouts"
      ]
    }
  }
}